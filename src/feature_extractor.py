# -*- coding: utf-8 -*-
"""Feature_Extraction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/marivenkateshm/feature-extraction.89c4e675-d6e3-47c0-afee-deb434dff10d.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20251113/auto/storage/goog4_request%26X-Goog-Date%3D20251113T134611Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D7a5e6e7f1f376d2df3e13df5c40076efb2cb463fa8d019dcb5718069170dbc1435ba008b6840785aada59d06b4f07f24a58fae9f6efd46aba6235f4572d7431c105cb11d3878b7db74ff3e222731ce1756abb014b0e11e5d6921f26836a62ef3f604127bf4ff9f9f2691f1150d85e69eb9e997eb6e0df063e3a1dc344f56da9ae575ede8d2010ce141649031701713473a7260c109986064a5d15d566ea20b3f79c915b26b7618fda1d5f66050b1b06de380a3138c05266109a9f686d3e3abb4c3c9ca26db28a7283c23ba4ba269eb15b727c7903535f1be98ba58714217c8c7191e7acb4a156062db792862741876d2953c9760be8ecb4b5201584dda47e775
"""

# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE
# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.
import kagglehub
kagglehub.login()

# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,
# THEN FEEL FREE TO DELETE THIS CELL.
# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON
# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR
# NOTEBOOK.

chrisfilo_urbansound8k_path = kagglehub.dataset_download('chrisfilo/urbansound8k')
marivenkateshm_dog_audio_path = kagglehub.dataset_download('marivenkateshm/dog-audio')
marivenkateshm_meta_data_path = kagglehub.dataset_download('marivenkateshm/meta-data')
marivenkateshm_car_horn_path = kagglehub.dataset_download('marivenkateshm/car-horn')
marivenkateshm_updatedata_path = kagglehub.dataset_download('marivenkateshm/updatedata')

print('Data source import complete.')

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

"""## Audio Classification Using Machine Learning PR Project##"""

!pip install librosa

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt
# %matplotlib inline

filename = '/kaggle/input/dog-audio/dog_bark.wav'

!pip install Ipython
import IPython.display as ipd

import librosa
import librosa.display
plt.figure(figsize=(14,5))
data,sample_rate = librosa.load(filename) #load audio
librosa.display.waveshow(data,sr=sample_rate)
plt.title("Dog_bark Audio Signal")
plt.xlabel("Time(s)")
plt.ylabel("Amp")
plt.show()
ipd.Audio(filename) #play audio

audio = '/kaggle/input/car-horn/car_horn.wav'
plt.figure(figsize=(14,5))
data_1,sample_rate1 = librosa.load(audio)
librosa.display.waveshow(data_1,sr=sample_rate1)
plt.title('carhorn audio signal')
plt.show()
ipd.Audio(audio)

sample_rate #how many tim es per second a sound is sampled

data

import pandas as pd
metadata = pd.read_csv('/kaggle/input/meta-data/metadata/UrbanSound8K.csv')
metadata.head(10)

#to check wheather the dataset is balanced or imbalanced
metadata['class'].value_counts()

"""looks like its balanced**

#Lets read with scipy****
"""

from scipy.io import wavfile as wav
wave_sr,wave_audio = wav.read(filename)
wave_audio

"""***we see two features so they are in two channels and not normalized.****"""

#original audio signal with 2 channel
plt.figure(figsize=(14,5))
plt.plot(wave_audio)

"""****Mel-Frequency Cepstral Coefficients(MFCC)****"""

mfccs = librosa.feature.mfcc(y = data,sr = sample_rate)
print(mfccs.shape)

mfccs

"""****Feature Extraction****"""

import pandas as pd
import os
import librosa

audio_dataset_path = '/kaggle/input/audio-urban-sound-detection'
metadata = pd.read_csv("/kaggle/input/meta-data/metadata/UrbanSound8K.csv")
metadata.head(10)

import os
import numpy as np
import pandas as pd
import librosa
import pywt
from tqdm import tqdm
from scipy.stats import entropy

metadata_csv = "/kaggle/input/updatedata/UrbanSound8K_augmented.csv"
audio_dir = "/kaggle/input/urbansound8k"

metadata = pd.read_csv(metadata_csv)
print("Total files in metadata:", len(metadata))

def extract_features_from_audio(y, sr):
    """
    Extracts MFCC, Chroma, Spectral, Temporal, Entropy, Wavelet Energy
    with Nyquist-safe spectral contrast and resampling.
    """
    try:

        if len(y) < 0.25 * sr:
            return None


        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
        mfcc_delta = librosa.feature.delta(mfcc)
        mfcc_delta2 = librosa.feature.delta(mfcc, order=2)
        mfcc_features = np.hstack([
            np.mean(mfcc, axis=1),
            np.mean(mfcc_delta, axis=1),
            np.mean(mfcc_delta2, axis=1)
        ])


        chroma = np.mean(librosa.feature.chroma_stft(y=y, sr=sr).T, axis=0)  # 12


        centroid = np.mean(librosa.feature.spectral_centroid(y=y, sr=sr))
        bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=y, sr=sr))

        contrast = np.mean(librosa.feature.spectral_contrast(y=y, sr=sr, n_bands=6, fmin=200.0))
        rolloff = np.mean(librosa.feature.spectral_rolloff(y=y, sr=sr))
        flatness = np.mean(librosa.feature.spectral_flatness(y=y))
        spectral_features = [centroid, bandwidth, contrast, rolloff, flatness]


        zcr = np.mean(librosa.feature.zero_crossing_rate(y))
        rms = np.mean(librosa.feature.rms(y=y))
        temporal_features = [zcr, rms]


        S = np.abs(librosa.stft(y))
        ps = S / np.sum(S)
        spec_entropy = entropy(np.mean(ps, axis=1))
        spectral_entropy = [spec_entropy]


        coeffs = pywt.wavedec(y, 'db4', level=5)
        wavelet_energy = [np.sum(np.square(c)) for c in coeffs]

        features = np.hstack([
            mfcc_features,
            chroma,
            spectral_features,
            temporal_features,
            spectral_entropy,
            wavelet_energy
        ])
        return features

    except Exception as e:
        print(f"[Warning] Feature extraction failed: {e}")
        return None


def extract_features_from_dataset(metadata, audio_dir):
    features_list, labels_list = [], []

    print("\nStarting dataset-wide extraction...")
    for i, row in tqdm(metadata.iterrows(), total=len(metadata)):
        fold = row['fold']
        file_name = row['slice_file_name']
        label = row['classID']
        file_path = os.path.join(audio_dir, f"fold{fold}", file_name)

        if not os.path.exists(file_path):
            print(f"[Skip] Missing file: {file_path}")
            continue

        try:

            y, sr = librosa.load(file_path, sr=22050, mono=True)
            feats = extract_features_from_audio(y, sr)
            if feats is not None:
                features_list.append(feats)
                labels_list.append(label)
        except Exception as e:
            print(f"[Error] {file_name}: {e}")
            continue

        if i % 500 == 0 and i > 0:
            print(f"Processed {i} files...")

    if len(features_list) == 0:
        print(" No valid features extracted.")
        return np.empty((0,)), np.empty((0,))

    X = np.vstack(features_list)
    y = np.array(labels_list)
    print(f"\n Extraction Complete: {X.shape[0]} samples, {X.shape[1]} features each.")
    return X, y

X, y = extract_features_from_dataset(metadata, audio_dir)

if X.size > 0:
    np.save("X_features.npy", X)
    np.save("y_labels.npy", y)
    print("\n Saved:")
    print("   X_features.npy ->", X.shape)
    print("   y_labels.npy   ->", y.shape)

X = np.load("X_features.npy")
y = np.load("y_labels.npy")


feature_names = [f"feature_{i+1}" for i in range(X.shape[1])]
df = pd.DataFrame(X, columns=feature_names)

df["label"] = y

df.to_csv("UrbanSound8K_Features_Extract.csv", index=False)

print(" DataFrame created and saved as 'UrbanSound8K_Features_Extract.csv'")
print("Shape:", df.shape)
print(df.head())

df_FE = pd.read_csv("UrbanSound8K_Features_Extract.csv")
df_FE.head(10)

df_FE.describe()
print(df_FE["label"].value_counts())
